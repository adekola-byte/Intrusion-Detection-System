{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a758ebc4-0caf-4e55-9d65-a6fa8e30c9ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ids.v1d2a3zlbmcexhv0vqkb4vhzjg.phxx.internal.cloudapp.net:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Final_IDS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b5289dbc90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Final_IDS\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ff092b-b1b8-4d7a-afec-36441330027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyarrow as pa\n",
    "from pyspark.sql.types import DataType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.dataframe import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519092f8-f787-4096-a9eb-0e1a137929fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = spark.read.csv('NUSW-NB15_features.csv', header=\"true\", inferSchema=False)\n",
    "#resolving the columns containing features to a list in the order they appear to use as headers for the dataframe\n",
    "distinct_names = df_col.select(col(\"`No.`\").cast(\"int\"), \"Name\").distinct()\n",
    "ordered_dataset_names = [row.Name for row in distinct_names.orderBy(\"`No.`\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec33380-ea58-4b62-9e05-be7f4d7e9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "csv_files = [\"C:/users/python/UNSW-NB15_1.csv\", \"C:/users/python/UNSW-NB15_2.csv\", \"C:/users/python/UNSW-NB15_3.csv\", \"C:/users/python/UNSW-NB15_4.csv\"]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = spark.read.option('header', False).csv(csv_file)\n",
    "    renamed_df = df.toDF(*ordered_dataset_names)\n",
    "    dfs.append(renamed_df)\n",
    "\n",
    "def union_all(*dfss):\n",
    "    return reduce(DataFrame.unionAll, dfss)\n",
    "\n",
    "\n",
    "dataframe = union_all(*dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942473b1-7ac3-4e00-84a2-aff9787440e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.na.fill('normal', ['attack_cat'])\n",
    "dataframe = dataframe.na.fill('0', ['ct_flw_http_mthd'])\n",
    "dataframe = dataframe.na.fill('0', ['is_ftp_login'])\n",
    "dataframe = dataframe.withColumn(\"is_ftp_login\", F.when(F.col(\"is_ftp_login\") > 1, 1).otherwise(F.col(\"is_ftp_login\")))\n",
    "dataframe = dataframe.withColumn(\"service\", F.when(F.col(\"service\") == \"-\", None).otherwise(F.col(\"service\")))\n",
    "dataframe = dataframe.fillna(\"unknown\", [\"service\"])\n",
    "dataframe = dataframe.fillna(\"0\", [\"sport\"])\n",
    "dataframe = dataframe.fillna(\"0\", [\"dsport\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9af061-9c37-40d9-9204-3c2fe7cd885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resolving the ip address columns from string to numeric type while preserving the value\n",
    "dataframe = dataframe.withColumn(\"srcip_int\",split(col(\"srcip\"),\"\\.\")[0]*16777216 +split(col(\"srcip\"),\"\\.\")[1]*65536+ split(col(\"srcip\"),\"\\.\")[2]*256 + split(col(\"srcip\"),\"\\.\")[3])\n",
    "dataframe = dataframe.withColumn(\"dstip_int\",split(col(\"dstip\"),\"\\.\")[0]*16777216 +split(col(\"dstip\"),\"\\.\")[1]*65536+ split(col(\"dstip\"),\"\\.\")[2]*256 + split(col(\"dstip\"),\"\\.\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ef58bc-7768-4353-9847-0adc8c950a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\"dur\", \"dload\", \"sload\", \"sjit\", \"djit\", \"Sintpkt\", \"Dintpkt\", \"tcprtt\", \"synack\", \"ackdat\"]\n",
    "for col_name in columns_to_convert:\n",
    "    dataframe = dataframe.withColumn(col_name, dataframe[col_name].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa41767a-18af-4482-abb8-8c0bdfeaa698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying the columns to exclude from the transformation of dataframe from string type to double type\n",
    "#'srcip','dstip' will be dropped so no need to transform that, 'srcip_int' and 'dstip_int' have been transformed to int type, the rest are nominal datatypes that will be transformed later user stringindexer\n",
    "columns_to_exclude = [\"srcip\", \"dstip\", \"srcip_int\",\"dstip_int\",\"proto\", \"state\", \"service\",\"attack_cat\", \"dur\", \"dload\", \"sload\", \"sjit\", \"djit\", \"Sintpkt\" , \"Dintpkt\",\"tcprtt\", \"synack\", \"ackdat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0952c0b7-e836-4316-9903-ef8b43c176ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing stringindexing of the nominal datatypes\n",
    "for col_name, col_type in dataframe.dtypes:\n",
    "        if col_name not in columns_to_exclude:\n",
    "            dataframe = dataframe.withColumn(col_name, dataframe[col_name].cast(\"int\"))\n",
    "columns_to_convert = [\"proto\", \"state\", \"service\", \"attack_cat\"]\n",
    "indexers = [StringIndexer(inputCol=\"proto\", outputCol=\"proto_index\", handleInvalid=\"skip\"), StringIndexer(inputCol=\"state\", outputCol=\"state_index\", handleInvalid=\"skip\"),StringIndexer(inputCol=\"service\", outputCol=\"service_index\",  handleInvalid=\"skip\"),StringIndexer(inputCol=\"attack_cat\", outputCol=\"attackcat_index\",  handleInvalid=\"skip\")]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "dataframe_r = pipeline.fit(dataframe).transform(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4caaba-8552-431c-b367-0eca231482a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns to drop after transformation, ct_ftp_cmd was dropped due to having about half null values\n",
    "cols = (\"srcip\", \"dstip\", \"proto\",\"state\",\"service\", \"attack_cat\", \"ct_ftp_cmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dc603a3-077c-4051-a49e-12db768c6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_d = dataframe_r.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e2a879-b157-4d2b-a6d4-2b4300d66f84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2540047\n",
      "Number of columns: 51\n"
     ]
    }
   ],
   "source": [
    "num_rows = dataframe.count()\n",
    "num_columns = len(dataframe.columns)\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4787f75e-fb4e-4f42-acbd-417e5cfe9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = dataframe_d.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3b17cd-f483-46fc-b23b-4c91a606d274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sbytes and sloss: 0.95\n",
      "Correlation between dbytes and dloss: 0.99\n",
      "Correlation between dbytes and Dpkts: 0.97\n",
      "Correlation between sttl and ct_state_ttl: 0.93\n",
      "Correlation between sttl and Label: 0.95\n",
      "Correlation between dloss and Dpkts: 0.99\n",
      "Correlation between swin and dwin: 0.99\n",
      "Correlation between stcpb and dtcpb: 0.96\n",
      "Correlation between Stime and Ltime: 1.00\n",
      "Correlation between tcprtt and synack: 0.92\n",
      "Correlation between tcprtt and ackdat: 0.92\n",
      "Correlation between ct_srv_src and ct_srv_dst: 0.98\n",
      "Correlation between ct_srv_src and ct_dst_src_ltm: 0.97\n",
      "Correlation between ct_srv_dst and ct_dst_src_ltm: 0.98\n",
      "Correlation between ct_dst_ltm and ct_src_ ltm: 0.96\n",
      "Correlation between ct_dst_ltm and ct_src_dport_ltm: 0.98\n",
      "Correlation between ct_src_ ltm and ct_src_dport_ltm: 0.97\n",
      "Correlation between ct_src_dport_ltm and ct_dst_sport_ltm: 0.92\n",
      "Correlation between ct_src_dport_ltm and ct_dst_src_ltm: 0.90\n"
     ]
    }
   ],
   "source": [
    "#feature selection on training dataset, first transform columns to vector form  \n",
    "#then find highly correlated columns\n",
    "corr_columns = training.columns\n",
    "vec_assembler = VectorAssembler(inputCols=corr_columns, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "corr_df_vector = vec_assembler.transform(training).select(\"features\")\n",
    "correlation_matrix = Correlation.corr(corr_df_vector, \"features\")\n",
    "correlations = correlation_matrix.head()[0].toArray()\n",
    "for i in range(len(corr_columns)):\n",
    "    for j in range(i + 1, len(corr_columns)):\n",
    "        col1 = corr_columns[i]\n",
    "        col2 = corr_columns[j]\n",
    "        correlation_value = correlations[i, j]\n",
    "        if correlation_value > 0.9:\n",
    "            print(f\"Correlation between {col1} and {col2}: {correlation_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86cab830-e637-448c-957b-1a6df6ef8687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ct_srv_dst', 'ct_src_ ltm', 'ct_src_dport_ltm', 'ct_dst_src_ltm', 'dtcpb', 'dwin', 'Ltime', 'dloss', 'Dpkts'}\n"
     ]
    }
   ],
   "source": [
    "#dropping one of the columns with a correlation higher than 0.95\n",
    "to_drop = set()\n",
    "for i in range(len(corr_columns)):\n",
    "    for j in range(i + 1, len(corr_columns)):\n",
    "        col1 = corr_columns[i]\n",
    "        col2 = corr_columns[j]\n",
    "        correlation_value = correlations[i, j]\n",
    "        if correlation_value > 0.95:\n",
    "            # Add one of the correlated features to the list to_drop\n",
    "            to_drop.add(col2)\n",
    "\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ac4576-1c31-4115-a594-81f7ef166e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highly correlated features, attackcat_index is for multiclassification which will be used later, srcip, dstip,sport, and dsport will ideally not be available in training data\n",
    "columns_to_drop = ('ct_srv_dst', 'Ltime', 'ct_dst_src_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'dloss', 'Dpkts', 'dwin', 'dtcpb', 'attackcat_index', 'srcip', 'dstip', 'sport', 'dsport', 'srcip_int','dstip_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ee5132a-5ffc-4ec3-9915-e4c1c5c93308",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = training.drop(*map(str, columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd76571-16d4-46b9-a567-b774b4bc3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing the dataset and excluding the label\n",
    "columns = training_d.columns\n",
    "column_to_exclude = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2020007d-747e-417b-97d4-0b29de4fd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in columns if col != column_to_exclude]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features', handleInvalid='skip')\n",
    "temptraining = assembler.transform(training_d)\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "training = scaler.fit(temptraining).transform(temptraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b98d68-1e7c-4ed0-b32c-3f29c77bfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = test.drop(*map(str, columns_to_drop))\n",
    "feature_columns = [col for col in columns if col != column_to_exclude]\n",
    "temptest = assembler.transform(test_d)\n",
    "test = scaler.fit(temptest).transform(temptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aca45d3-e471-4737-8a82-943872ba0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.withColumnRenamed('Label', 'label')\n",
    "test = test.withColumnRenamed('Label', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc1a2555-822b-4629-af6d-54544d01c809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9470005726026475\n",
      "False Alarm Rate: 0.013871319955792865\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol='label', featuresCol='scaled_features')\n",
    "lr_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=lr_param_grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "model = tvs.fit(training)\n",
    "best_model = model.bestModel\n",
    "predictions = best_model.transform(test)\n",
    "true_positives = predictions.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"False Alarm Rate:\", false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca75ca52-5426-4c38-834b-f3ea58535631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9966634557088376\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions)\n",
    "print(\"AUC Score:\", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e941c5a4-8fa2-49a4-9474-5bc99bae612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_F1 Score: 0.9792076928978798\n",
      "rf_False Alarm Rate: 0.0050365507782852426\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_rf = TrainValidationSplit(estimator=rf,\n",
    "                              estimatorParamMaps=rf_param_grid,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              trainRatio=0.8)\n",
    "\n",
    "model_rf = tvs_rf.fit(training)\n",
    "best_model_rf = model_rf.bestModel\n",
    "predictions_rf = best_model_rf.transform(test)\n",
    "true_positives = predictions_rf.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_rf.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_rf.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_rf.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"rf_F1 Score:\", f1_score)\n",
    "print(\"rf_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5ceb796-85e6-48eb-9d4a-a5f36e12ad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_AUC Score: 0.9997484738247867\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions_rf)\n",
    "print(\"rf_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa621f67-2906-4654-927d-c484a3a05bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "243d08df-1c96-4edc-932d-43235548ba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_F1 Score: 0.9409347714432461\n",
      "svm_False Alarm Rate: 0.015089679231967617\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(labelCol='label', featuresCol='scaled_features')\n",
    "svm_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.maxIter, [10, 100]) \\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_svm = TrainValidationSplit(estimator=svm,\n",
    "                               estimatorParamMaps=svm_param_grid,\n",
    "                               evaluator=BinaryClassificationEvaluator(),\n",
    "                               trainRatio=0.8)\n",
    "model_svm = tvs_svm.fit(training)\n",
    "best_model_svm = model_svm.bestModel\n",
    "predictions_svm = best_model_svm.transform(test)\n",
    "true_positives = predictions_svm.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_svm.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_svm.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_svm.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"svm_F1 Score:\", f1_score)\n",
    "print(\"svm_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e80c787-95e2-4cf6-b4c6-2a95ef7da67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_AUC Score: 0.9962330248401873\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions_svm)\n",
    "print(\"svm_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9d9223b-52ad-4b47-80cb-995da9c68ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1e7b63a-8aff-4746-86ad-d30cfd90cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_F1 Score: 0.9751789405353696\n",
      "dt_False Alarm Rate: 0.005439341686528808\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "dt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_dt = TrainValidationSplit(estimator=dt,\n",
    "                              estimatorParamMaps=dt_param_grid,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              trainRatio=0.8)\n",
    "model_dt = tvs_dt.fit(training)\n",
    "best_model_dt = model_dt.bestModel\n",
    "predictions_dt = best_model_dt.transform(test)\n",
    "true_positives = predictions_dt.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_dt.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_dt.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_dt.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"dt_F1 Score:\", f1_score)\n",
    "print(\"dt_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58e1ac8e-beff-4859-8c11-3029194be131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_AUC Score: 0.9987333531687295\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions_dt)\n",
    "print(\"dt_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5b3a2dd-a0b6-4f7e-84d6-60912f715f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4efb86cb-0b45-49d7-ba92-fa8bd86f3956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_F1 Score: 0.97691886527735\n",
      "gbt_False Alarm Rate: 0.004783558141702508\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "gbt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10]) \\\n",
    "    .addGrid(gbt.maxIter, [20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_gbt = TrainValidationSplit(estimator=gbt,\n",
    "                               estimatorParamMaps=gbt_param_grid,\n",
    "                               evaluator=BinaryClassificationEvaluator(),\n",
    "                               trainRatio=0.8)\n",
    "\n",
    "model_gbt = tvs_gbt.fit(training)\n",
    "best_model_gbt = model_gbt.bestModel\n",
    "predictions_gbt = best_model_gbt.transform(test)\n",
    "true_positives = predictions_gbt.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_gbt.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_gbt.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_gbt.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"gbt_F1 Score:\", f1_score)\n",
    "print(\"gbt_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78e2b72e-3f20-4dda-8b21-c0f065e8f664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_AUC Score: 0.9995923329515508\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions_gbt)\n",
    "print(\"gbt_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b42629f-f4d4-4add-a3f2-73e7cfaa7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['features', 'scaled_features', 'label']\n",
    "feature_names = [col for col in training.columns if col not in exclude_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e15cbc52-29cc-46f1-b2c0-f15b9356eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "ct_state_ttl: 0.9242375702149693\n",
      "smeansz: 0.025926133409351515\n",
      "sbytes: 0.023579427043580164\n",
      "ct_srv_src: 0.009015875079260985\n",
      "dmeansz: 0.004070826247022661\n",
      "proto_index: 0.003224146417374436\n",
      "sttl: 0.0020769488557484997\n",
      "dttl: 0.001728203694154997\n",
      "Spkts: 0.001166171033622853\n",
      "dbytes: 0.0007900842083220633\n",
      "Dintpkt: 0.0006339058617094622\n",
      "sloss: 0.0005365312225968248\n",
      "service_index: 0.0005068647661865191\n",
      "Stime: 0.00048276453879922567\n",
      "djit: 0.0004291331478325324\n",
      "ackdat: 0.0004054697498145416\n",
      "sjit: 0.000388074781368542\n",
      "ct_src_ ltm: 0.00023932742296264365\n",
      "dur: 0.00012750631093002\n",
      "ct_dst_ltm: 0.0001227081698673326\n",
      "res_bdy_len: 0.00011757859249464134\n",
      "sload: 4.7925049199221146e-05\n",
      "trans_depth: 4.219527382872446e-05\n",
      "stcpb: 3.365870132567805e-05\n",
      "ct_dst_sport_ltm: 3.0344821362307025e-05\n",
      "swin: 2.2317715778035818e-05\n",
      "dload: 7.66941901848868e-06\n",
      "Sintpkt: 5.861616369824903e-06\n",
      "ct_flw_http_mthd: 4.122571991452658e-06\n",
      "is_ftp_login: 6.540631562102726e-07\n",
      "tcprtt: 0.0\n",
      "synack: 0.0\n",
      "is_sm_ips_ports: 0.0\n",
      "state_index: 0.0\n"
     ]
    }
   ],
   "source": [
    "decision_tree_model = best_model_dt\n",
    "feature_importances = decision_tree_model.featureImportances\n",
    "feature_importance_dict = {}\n",
    "for feature_name, importance in zip(feature_names, feature_importances):\n",
    "    feature_importance_dict[feature_name] = importance\n",
    "\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Feature Importances:\")\n",
    "for feature_name, importance in sorted_feature_importance:\n",
    "    print(f\"{feature_name}: {importance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7909194d-70b4-49e9-be81-d6a97bd2218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns less than 0.0001\n",
    "columns_to_drop = ('state_index','dload', 'dur','is_sm_ips_ports', 'sload','res_bdy_len','is_ftp_login','synack','ct_dst_ltm'\n",
    "                   'tcprtt' ,'swin', 'sjit','Sintpkt', 'ct_flw_http_mthd', 'ct_src_ ltm','stcpb' ,'ct_dst_sport_ltm', 'trans_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdf239cd-8b5f-4f6d-9f64-f897d3da606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sf = training_d.drop(*map(str, columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f673863-e73c-4a23-82c9-c029945b5abd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#standardizing the dataset and excluding the label\n",
    "columns = training_sf.columns\n",
    "column_to_exclude = 'Label'\n",
    "feature_columns = [col for col in columns if col != column_to_exclude]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features', handleInvalid='skip')\n",
    "temptraining = assembler.transform(training_sf)\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "training = scaler.fit(temptraining).transform(temptraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edff089a-4fc1-4f98-b35b-179f35b56624",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_sf = test_d.drop(*map(str, columns_to_drop))\n",
    "temptest = assembler.transform(test_sf)\n",
    "test = scaler.fit(temptest).transform(temptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6925675f-7396-4b0f-a090-5d268c58cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.withColumnRenamed('Label', 'label')\n",
    "test = test.withColumnRenamed('Label', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af96f238-c8e9-4a29-a426-ede752543799",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap: True\n",
      "cacheNodeIds: False\n",
      "checkpointInterval: 10\n",
      "featureSubsetStrategy: auto\n",
      "featuresCol: scaled_features\n",
      "impurity: gini\n",
      "labelCol: label\n",
      "leafCol: \n",
      "maxBins: 32\n",
      "maxDepth: 15\n",
      "maxMemoryInMB: 256\n",
      "minInfoGain: 0.0\n",
      "minInstancesPerNode: 1\n",
      "minWeightFractionPerNode: 0.0\n",
      "numTrees: 50\n",
      "predictionCol: prediction\n",
      "probabilityCol: probability\n",
      "rawPredictionCol: rawPrediction\n",
      "seed: -3555532632180229690\n",
      "subsamplingRate: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model_params = best_model_rf.extractParamMap()\n",
    "for param_name, param_value in best_model_params.items():\n",
    "    print(f\"{param_name.name}: {param_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "530ac846-8a5e-49b3-b879-45ff5d914322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_F1 Score: 0.9690197991436115\n",
      "rf_False Alarm Rate: 0.005325158786962139\n"
     ]
    }
   ],
   "source": [
    "model_rf = tvs_rf.fit(training)\n",
    "best_model_rf = model_rf.bestModel\n",
    "predictions_rf = best_model_rf.transform(test)\n",
    "true_positives = predictions_rf.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_rf.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_rf.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_rf.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"rf_F1 Score:\", f1_score)\n",
    "print(\"rf_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "511cbad1-7bb6-4860-b291-2d7efa85bcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_AUC Score: 0.9996176878808688\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions_rf)\n",
    "print(\"rf_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fad797df-bb62-454d-aefc-e4f56a3349d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_F1 Score: 0.9641101661855348\n",
      "dt_False Alarm Rate: 0.004899776280311317\n"
     ]
    }
   ],
   "source": [
    "model_dt = tvs_dt.fit(training)\n",
    "best_model_dt = model_dt.bestModel\n",
    "predictions_dt = best_model_dt.transform(test)\n",
    "true_positives = predictions_dt.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_dt.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_dt.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_dt.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"dt_F1 Score:\", f1_score)\n",
    "print(\"dt_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7c7978b-7f46-4c88-98eb-f9bea1bb2c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_AUC Score: 0.9982006363350612\n"
     ]
    }
   ],
   "source": [
    "auc_score = evaluator_auc.evaluate(predictions_dt)\n",
    "print(\"dt_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e4de532-8f1b-44d5-9071-50771920b663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_F1 Score: 0.9671824973319104\n",
      "gbt_False Alarm Rate: 0.0035988710483315554\n"
     ]
    }
   ],
   "source": [
    "model_gbt = tvs_gbt.fit(training)\n",
    "best_model_gbt = model_gbt.bestModel\n",
    "predictions_gbt = best_model_gbt.transform(test)\n",
    "true_positives = predictions_gbt.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_gbt.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_gbt.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_gbt.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"gbt_F1 Score:\", f1_score)\n",
    "print(\"gbt_False Alarm Rate:\", false_alarm_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33f5bf06-a7ff-42dd-bae1-a13fb06acd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_AUC Score: 0.9994018130885248\n"
     ]
    }
   ],
   "source": [
    "auc_score = evaluator_auc.evaluate(predictions_gbt)\n",
    "print(\"gbt_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62666bf4-878e-4b79-a542-93af4a8d8af9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----+-----+-----+-------+-------+----+----------+-------+------+------+------------+----------+----------+-----+-----------+-------------+\n",
      "|sbytes|dbytes|sttl|dttl|sloss|Spkts|smeansz|dmeansz|djit|     Stime|Dintpkt|tcprtt|ackdat|ct_state_ttl|ct_srv_src|ct_dst_ltm|Label|proto_index|service_index|\n",
      "+------+------+----+----+-----+-----+-------+-------+----+----------+-------+------+------+------------+----------+----------+-----+-----------+-------------+\n",
      "|   147|     0|  64|   0|    0|    1|    147|      0| 0.0|1421929277|    0.0|   0.0|   0.0|           0|         2|         2|    0|        6.0|          0.0|\n",
      "|   200|     0| 254|   0|    0|    2|    100|      0| 0.0|1421930680|    0.0|   0.0|   0.0|           2|        12|         4|    0|      134.0|          0.0|\n",
      "|  2800|     0|  64|   0|    0|   20|    140|      0| 0.0|1421931785|    0.0|   0.0|   0.0|           0|         2|         2|    0|        6.0|          0.0|\n",
      "|   147|     0|  64|   0|    0|    1|    147|      0| 0.0|1421929277|    0.0|   0.0|   0.0|           0|         2|         2|    0|        6.0|          0.0|\n",
      "|   264|     0|  64|   0|    0|    3|     88|      0| 0.0|1421928800|    0.0|   0.0|   0.0|           0|         2|         2|    0|        6.0|          0.0|\n",
      "+------+------+----+----+-----+-----+-------+-------+----+----------+-------+------+------+------------+----------+----------+-----+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_sf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d29b0-ebf8-41d0-bb86-19654fb4ea87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
