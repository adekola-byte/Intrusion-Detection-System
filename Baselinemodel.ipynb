{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42821b1b-4129-4298-a4e1-0e2223fb55bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ids.v1d2a3zlbmcexhv0vqkb4vhzjg.phxx.internal.cloudapp.net:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Final_IDS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x18f9d1b0350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Final_IDS\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76e838e-f3f6-4f4c-b98b-ea47bc0765bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pyarrow as pa\n",
    "from pyspark.sql.types import DataType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.dataframe import *\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, TrainValidationSplit\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59599c6e-7bcf-4f81-82ab-53ffb837e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = spark.read.csv('NUSW-NB15_features.csv', header=\"true\", inferSchema=False)\n",
    "#resolving the columns containing features to a list in the order they appear to use as headers for the dataframe\n",
    "distinct_names = df_col.select(col(\"`No.`\").cast(\"int\"), \"Name\").distinct()\n",
    "ordered_dataset_names = [row.Name for row in distinct_names.orderBy(\"`No.`\").collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910ea3a5-0bed-4436-830e-6743017f8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "csv_files = [\"C:/users/python/UNSW-NB15_1.csv\", \"C:/users/python/UNSW-NB15_2.csv\", \"C:/users/python/UNSW-NB15_3.csv\", \"C:/users/python/UNSW-NB15_4.csv\"]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = spark.read.option('header', False).csv(csv_file)\n",
    "    renamed_df = df.toDF(*ordered_dataset_names)\n",
    "    dfs.append(renamed_df)\n",
    "\n",
    "def union_all(*dfss):\n",
    "    return reduce(DataFrame.unionAll, dfss)\n",
    "\n",
    "\n",
    "dataframe = union_all(*dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb77382-7d43-4300-8136-351b76a7baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.na.fill('normal', ['attack_cat'])\n",
    "dataframe = dataframe.na.fill('0', ['ct_flw_http_mthd'])\n",
    "dataframe = dataframe.na.fill('0', ['is_ftp_login'])\n",
    "dataframe = dataframe.withColumn(\"is_ftp_login\", F.when(F.col(\"is_ftp_login\") > 1, 1).otherwise(F.col(\"is_ftp_login\")))\n",
    "dataframe = dataframe.withColumn(\"service\", F.when(F.col(\"service\") == \"-\", None).otherwise(F.col(\"service\")))\n",
    "dataframe = dataframe.fillna(\"unknown\", [\"service\"])\n",
    "dataframe = dataframe.fillna(\"0\", [\"sport\"])\n",
    "dataframe = dataframe.fillna(\"0\", [\"dsport\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94545102-5c2f-4ec7-84b0-83991a17b9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resolving the ip address columns from string to numeric type while preserving the value\n",
    "dataframe = dataframe.withColumn(\"srcip_int\",split(col(\"srcip\"),\"\\.\")[0]*16777216 +split(col(\"srcip\"),\"\\.\")[1]*65536+ split(col(\"srcip\"),\"\\.\")[2]*256 + split(col(\"srcip\"),\"\\.\")[3])\n",
    "dataframe = dataframe.withColumn(\"dstip_int\",split(col(\"dstip\"),\"\\.\")[0]*16777216 +split(col(\"dstip\"),\"\\.\")[1]*65536+ split(col(\"dstip\"),\"\\.\")[2]*256 + split(col(\"dstip\"),\"\\.\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c4ec37-a08c-4461-b6e0-4f299423f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\"dur\", \"dload\", \"sload\", \"sjit\", \"djit\", \"Sintpkt\", \"Dintpkt\", \"tcprtt\", \"synack\", \"ackdat\"]\n",
    "for col_name in columns_to_convert:\n",
    "    dataframe = dataframe.withColumn(col_name, dataframe[col_name].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13442bfe-43d1-44da-a752-9944c71e473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying the columns to exclude from the transformation of dataframe from string type to double type\n",
    "#'srcip','dstip' will be dropped so no need to transform that, 'srcip_int' and 'dstip_int' have been transformed to int type, the rest are nominal datatypes that will be transformed later user stringindexer\n",
    "columns_to_exclude = [\"srcip\", \"dstip\", \"srcip_int\",\"dstip_int\",\"proto\", \"state\", \"service\",\"attack_cat\", \"dur\", \"dload\", \"sload\", \"sjit\", \"djit\", \"Sintpkt\" , \"Dintpkt\",\"tcprtt\", \"synack\", \"ackdat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c48b7a3-8cc0-45f7-a075-f5997aa0d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing stringindexing of the nominal datatypes\n",
    "for col_name, col_type in dataframe.dtypes:\n",
    "        if col_name not in columns_to_exclude:\n",
    "            dataframe = dataframe.withColumn(col_name, dataframe[col_name].cast(\"int\"))\n",
    "columns_to_convert = [\"proto\", \"state\", \"service\", \"attack_cat\"]\n",
    "indexers = [StringIndexer(inputCol=\"proto\", outputCol=\"proto_index\", handleInvalid=\"skip\"), StringIndexer(inputCol=\"state\", outputCol=\"state_index\", handleInvalid=\"skip\"),StringIndexer(inputCol=\"service\", outputCol=\"service_index\",  handleInvalid=\"skip\"),StringIndexer(inputCol=\"attack_cat\", outputCol=\"attackcat_index\",  handleInvalid=\"skip\")]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "dataframe_r = pipeline.fit(dataframe).transform(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fcb04f4-cd90-48d5-b693-dec58f264f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (\"srcip\", \"dstip\", \"proto\",\"state\",\"service\", \"attack_cat\", \"ct_ftp_cmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c84e181b-889c-4b20-8e4f-0bf52361327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_d = dataframe_r.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6846a7b8-c361-4f84-a212-fac046a6e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = dataframe_d.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "214349de-8e28-4d72-895f-49fd557c78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack cat is for multiclassification, srcip,dstip, sport,dsport, and the int versions of srcip and dstip are dropped\n",
    "columns_to_drop = ('attackcat_index', 'srcip', 'dstip', 'sport', 'dsport', 'srcip_int', 'dstip_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d34031-45fd-495e-be25-697efe9aaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = training.drop(*map(str, columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed62222-8c7d-42be-8d3d-21863f7227e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing the dataset and excluding the label\n",
    "columns = training_d.columns\n",
    "column_to_exclude = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b19a520c-b070-43c0-8458-4422ef6019bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in columns if col != column_to_exclude]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features', handleInvalid='skip')\n",
    "temptraining = assembler.transform(training_d)\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "training = scaler.fit(temptraining).transform(temptraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ed711c-b308-4c26-9aae-a55bf6d9cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = test.drop(*map(str, columns_to_drop))\n",
    "temptest = assembler.transform(test_d)\n",
    "test = scaler.fit(temptest).transform(temptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64818b62-993b-46c4-b57a-090b6c229ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.withColumnRenamed('Label', 'label')\n",
    "test = test.withColumnRenamed('Label', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dfcc7ff-323f-41bb-afa9-5abcd4d0739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9613000204573553\n",
      "False Alarm Rate: 0.012976256212037547\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol='label', featuresCol='scaled_features')\n",
    "lr_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=lr_param_grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)\n",
    "model = tvs.fit(training)\n",
    "best_model = model.bestModel\n",
    "predictions = best_model.transform(test)\n",
    "true_positives = predictions.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"False Alarm Rate:\", false_alarm_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd7d5f3e-f8f4-4d8b-8762-0abeb368e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9963040710896558\n"
     ]
    }
   ],
   "source": [
    "evaluator_auc = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction')\n",
    "auc_score = evaluator_auc.evaluate(predictions)\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46751887-c76c-4d56-8bab-817ca5b18ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_F1 Score: 0.9854765071718733\n",
      "rf_False Alarm Rate: 0.0044393608722708665\n",
      "rf_AUC Score: 0.9998539982433695\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_rf = TrainValidationSplit(estimator=rf,\n",
    "                              estimatorParamMaps=rf_param_grid,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              trainRatio=0.8)\n",
    "\n",
    "model_rf = tvs_rf.fit(training)\n",
    "best_model_rf = model_rf.bestModel\n",
    "predictions_rf = best_model_rf.transform(test)\n",
    "true_positives = predictions_rf.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_rf.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_rf.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_rf.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"rf_F1 Score:\", f1_score)\n",
    "print(\"rf_False Alarm Rate:\", false_alarm_rate)\n",
    "auc_score = evaluator_auc.evaluate(predictions_rf)\n",
    "print(\"rf_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f68ae916-a9b6-4f40-b805-bec81a21d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "105e5d00-1692-4951-b25c-c53e5b60b728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_F1 Score: 0.9621809292685952\n",
      "svm_False Alarm Rate: 0.013843969393389603\n",
      "svm_AUC Score: 0.9964232647552888\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(labelCol='label', featuresCol='scaled_features')\n",
    "svm_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.maxIter, [10, 100]) \\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_svm = TrainValidationSplit(estimator=svm,\n",
    "                               estimatorParamMaps=svm_param_grid,\n",
    "                               evaluator=BinaryClassificationEvaluator(),\n",
    "                               trainRatio=0.8)\n",
    "model_svm = tvs_svm.fit(training)\n",
    "best_model_svm = model_svm.bestModel\n",
    "predictions_svm = best_model_svm.transform(test)\n",
    "true_positives = predictions_svm.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_svm.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_svm.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_svm.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"svm_F1 Score:\", f1_score)\n",
    "print(\"svm_False Alarm Rate:\", false_alarm_rate)\n",
    "auc_score = evaluator_auc.evaluate(predictions_svm)\n",
    "print(\"svm_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e80918b-988d-4612-8fad-7b2fa24971bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0041a9c2-cf1c-46d3-802a-bad0fee16025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_F1 Score: 0.9814850127579976\n",
      "dt_False Alarm Rate: 0.002866082932344666\n",
      "dt_AUC Score: 0.9994499606650452\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "dt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_dt = TrainValidationSplit(estimator=dt,\n",
    "                              estimatorParamMaps=dt_param_grid,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              trainRatio=0.8)\n",
    "model_dt = tvs_dt.fit(training)\n",
    "best_model_dt = model_dt.bestModel\n",
    "predictions_dt = best_model_dt.transform(test)\n",
    "true_positives = predictions_dt.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_dt.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_dt.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_dt.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"dt_F1 Score:\", f1_score)\n",
    "print(\"dt_False Alarm Rate:\", false_alarm_rate)\n",
    "auc_score = evaluator_auc.evaluate(predictions_dt)\n",
    "print(\"dt_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23d2024f-c0e0-4291-ae26-469b842f1229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09d051fc-b9e2-431c-8a10-87098044daa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt_F1 Score: 0.9839253892009734\n",
      "gbt_False Alarm Rate: 0.0032122917269245266\n",
      "gbt_AUC Score: 0.9998140903812993\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "gbt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10]) \\\n",
    "    .addGrid(gbt.maxIter, [20, 50]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_gbt = TrainValidationSplit(estimator=gbt,\n",
    "                               estimatorParamMaps=gbt_param_grid,\n",
    "                               evaluator=BinaryClassificationEvaluator(),\n",
    "                               trainRatio=0.8)\n",
    "\n",
    "model_gbt = tvs_gbt.fit(training)\n",
    "best_model_gbt = model_gbt.bestModel\n",
    "predictions_gbt = best_model_gbt.transform(test)\n",
    "true_positives = predictions_gbt.filter(\"label = 1 AND prediction = 1\").count()\n",
    "false_positives = predictions_gbt.filter(\"label = 0 AND prediction = 1\").count()\n",
    "true_negatives = predictions_gbt.filter(\"label = 0 AND prediction = 0\").count()\n",
    "false_negatives = predictions_gbt.filter(\"label = 1 AND prediction = 0\").count()\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "print(\"gbt_F1 Score:\", f1_score)\n",
    "print(\"gbt_False Alarm Rate:\", false_alarm_rate)\n",
    "auc_score = evaluator_auc.evaluate(predictions_gbt)\n",
    "print(\"gbt_AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b98f4666-a04d-4fb1-af90-fb5ecb108fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_d = dataframe_r.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c97f2a85-5445-49bb-ac0c-e6974cc45c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = dataframe_d.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "764667eb-411e-4507-9d14-204f5b8eca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ('Label', 'srcip', 'dstip', 'sport', 'dsport', 'srcip_int', 'dstip_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "559b40b2-ea04-4894-bb2c-d9307bd96b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_d = training.drop(*map(str, columns_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e717837c-a099-4c13-95b8-cb76204df36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing the dataset and excluding the label\n",
    "columns = training_d.columns\n",
    "column_to_exclude = 'attackcat_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c6ebde6-7d0a-4fdd-ab1d-830354f44d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in columns if col != column_to_exclude]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features', handleInvalid='skip')\n",
    "temptraining = assembler.transform(training_d)\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
    "training = scaler.fit(temptraining).transform(temptraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "324e01bd-5f65-4660-842f-23d5c6e558cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = test.drop(*map(str, columns_to_drop))\n",
    "temptest = assembler.transform(test_d)\n",
    "test = scaler.fit(temptest).transform(temptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e2605d6-c809-436c-aab6-c39f76bee15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.withColumnRenamed('attackcat_index', 'label')\n",
    "test = test.withColumnRenamed('attackcat_index', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd59cf9c-836f-44fe-abf3-12e9083c2d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9663811897856818\n",
      "False Alarm Rate: 0.028522615901736326\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "dt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_dt = TrainValidationSplit(estimator=dt,\n",
    "                              estimatorParamMaps=dt_param_grid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(),\n",
    "                              trainRatio=0.8)\n",
    "model_dt = tvs_dt.fit(training)\n",
    "best_model_dt = model_dt.bestModel\n",
    "predictions_gbt = best_model_dt.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol= 'label')\n",
    "f1_score = evaluator.evaluate(predictions_gbt, {evaluator.metricName: \"f1\"})\n",
    "print(\"F1 Score:\", f1_score)\n",
    "far = 1.0 - evaluator.evaluate(predictions_gbt, {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(\"False Alarm Rate:\", far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5ee12ae-12fb-4ba0-aeed-5867621632c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9713371120818522\n",
      "False Alarm Rate: 0.02473790940764775\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol='label', featuresCol='scaled_features')\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "tvs_rf = TrainValidationSplit(estimator=rf,\n",
    "                              estimatorParamMaps=rf_param_grid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(),\n",
    "                              trainRatio=0.8)\n",
    "\n",
    "model_rf = tvs_rf.fit(training)\n",
    "best_model_rf = model_rf.bestModel\n",
    "predictions_rf = best_model_rf.transform(test)\n",
    "f1_score = evaluator.evaluate(predictions_rf, {evaluator.metricName: \"f1\"})\n",
    "print(\"F1 Score:\", f1_score)\n",
    "far = 1.0 - evaluator.evaluate(predictions_rf, {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(\"False Alarm Rate:\", far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3b902-afd1-41e1-a3bb-b037db0ea44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
